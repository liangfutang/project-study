# 一. 重要组件操作实战
## 1.1 Namespace
名称空间用来隔离资源
```
kubectl create ns hello
kubectl delete ns hello
```
通过yaml创建
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: hello
```

## 1.2 Pod
运行中的一组容器，Pod是kubernetes中应用的最小单位.
```
# 创建pod,默认是创建在default空间
kubectl run mynginx --image=nginx

# 查看default名称空间的Pod
kubectl get pod 
# 描述
kubectl describe pod 你自己的Pod名字
# 删除
kubectl delete pod Pod名字
# 查看Pod的运行日志
kubectl logs Pod名字
kubectl logs -f Pod名字 # 日志追踪

# 每个Pod - k8s都会分配一个ip
kubectl get pod -owide
# 使用Pod的ip+pod里面运行容器的端口
curl 192.168.169.136

# 集群中的任意一个机器以及任意的应用都能通过Pod分配的ip来访问这个Pod
```

pod中但容器的
```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: mynginx
  name: mynginx # pod的名称
#  namespace: default
spec:
  containers:
  - image: nginx
    name: mynginx # 容器的名称
```

pod中多容器的,一个pod一个ip,通过端口访问到不同的容器，如，pod内有nginx和tomcat，80访问到nginx，8080访问到tomcat。pod内的容器间通过localhost加端口相互访问。
如果要在同一个pod中部署多个容器，需要暴露的端口不一致，否则后面的容器起不来，如果端口一定要一致则需要将容器放在不同的network网络空间
```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: myapp
  name: myapp
spec:
  containers:
  - image: nginx
    name: nginx
  - image: tomcat:8.5.68
    name: tomcat
```
**此时的应用还不能外部访问**

## 1.3 Deployment
控制Pod，使Pod拥有多副本，自愈，扩缩容等能力。使用`kubectl delete pod xxx`删除pod,run启动的会直接删掉，但是create deployment启动的pod会被删掉，但是会重新再启动一个。
```
# 清除所有Pod，比较下面两个命令有何不同效果？
kubectl run mynginx --image=nginx
# 上面是启动一个pod,如果要启动多个副本，则需要运行多次

# 创建一个pod或者创建pod时启动多个副本
kubectl create deployment mytomcat --image=tomcat:8.5.68
kubectl create deployment my-dep --image=nginx --replicas=3

# 动态的伸缩或扩容,或通过edit的方式修改yaml文件配置
kubectl scale --replicas=5 deployment/my-dep
kubectl edit deployment my-dep

# 滚动更新
# 语法：kubectl set image 工作负载方式/Pod名称 镜像名称=需要调整的镜像 --record
# --record 用作记录滚动更新的信息， 后面方便版本回退
kubectl set image deployment/my-dep nginx=nginx:1.16.1 --record
# 修改yaml文件的方式
kubectl edit deployment/my-dep

# 版本回退
#历史记录
kubectl rollout history deployment/my-dep
#查看某个历史详情
kubectl rollout history deployment/my-dep --revision=2
#回滚(回到上次)
kubectl rollout undo deployment/my-dep
#回滚(回到指定版本)
kubectl rollout undo deployment/my-dep --to-revision=2
```
yaml方式创建
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: my-dep
  name: my-dep
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-dep
  template:
    metadata:
      labels:
        app: my-dep
    spec:
      containers:
      - image: nginx
        name: nginx
```

更多：
除了Deployment，k8s还有 StatefulSet 、DaemonSet 、Job  等 类型资源。我们都称为 工作负载。
有状态应用使用  StatefulSet  部署，无状态应用使用 Deployment 部署
https://kubernetes.io/zh/docs/concepts/workloads/controllers/

```
Deployment:无状态应用部署，比如微服务，提供多副本等功能
StatefulSet:有状态应用部署，比如redis，提供稳定的存储、网络等功能
DaemonSet:守护型应用部署，比如日志收集组件，在每个机器都运行一份
Job/CronJob: 定时任务部署， 比如垃圾清理组件，可以在指定时间运行
```

# 1.4 Service
将一组 Pods 公开为网络服务的抽象方法。pod的服务发现与负载均衡

**ClusterIP方式：**
```
#暴露Deploy，默认是使用集群IP的方式，只能在宿主机或者集群其他pod中访问
# 可以通过IP方式：curl 10.96.20.78:8000
# 可以通过 servicename.namespace.svc:port (curl my-dep.default.svc:8000) 方式访问，此种方式不能在宿主机访问，只能在集群其他pod中访问
kubectl expose deployment my-dep --port=8000 --target-port=80
kubectl expose deployment my-dep --port=8000 --target-port=80 --type=ClusterIP
#使用标签检索Pod
kubectl get pod -l app=my-dep
```
通过yaml方式部署service
```yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: my-dep 
  name: my-dep
spec:
  selector:
    app: my-dep # 所有能访问的pod共用的一个标签
  ports:
  - port: 8000 # service暴露的端口
    protocol: TCP 
    targetPort: 80 # pod的端口
# type: ClusterIP # 默认集群IP的方式
```

**NodePort方式：**
```
kubectl expose deployment my-dep --port=8000 --target-port=80 --type=NodePort
```
通过yaml方式
```yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: my-dep
  name: my-dep
spec:
  ports:
  - port: 8000 # service端口
    protocol: TCP
    targetPort: 80 # pod端口
  selector:
    app: my-dep
  type: NodePort
```
NodePort范围在 30000-32767 之间   
NodePort的service除了自身的端口外还会随机的开一个对外暴露的端口，这个端口在每个服务器上都会打开，所以通过任意一个服务器的端口都能访问到这个service    
service自身的端口只能用service的IP在集群内访问，外网可以用公网IP加上暴露端口访问

# 1.5 Ingress
Service的统一网关入口      
官网地址：https://kubernetes.github.io/ingress-nginx/
就是nginx做的,外网可以通过http和https访问

安装
```
wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.47.0/deploy/static/provider/baremetal/deploy.yaml
#修改镜像
vi deploy.yaml
#将image的值改为如下值：
registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/ingress-nginx-controller:v0.46.0
# 检查安装的结果
kubectl get pod,svc -n ingress-nginx
# 最后别忘记安全组把svc暴露的端口要放行
# 安装完会有对应的pod，也会有两个service，一个对内的集群IP和一个对外的nodeport
```
搭建测试环境，部署两个deployment及其对应的service，以便后面能通过ingress网关路由到对应的应用上、
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-server
spec:
  replicas: 2
  selector:
    matchLabels:
      app: hello-server
  template:
    metadata:
      labels:
        app: hello-server
    spec:
      containers:
      - name: hello-server
        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server
        ports:
        - containerPort: 9000
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-demo
  name: nginx-demo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx-demo
  template:
    metadata:
      labels:
        app: nginx-demo
    spec:
      containers:
      - image: nginx
        name: nginx
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: nginx-demo
  name: nginx-demo
spec:
  selector:
    app: nginx-demo
  ports:
  - port: 8000
    protocol: TCP
    targetPort: 80
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hello-server
  name: hello-server
spec:
  selector:
    app: hello-server
  ports:
  - port: 8000
    protocol: TCP
    targetPort: 9000
```
Ingress网关路由添加
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress  
metadata:
  name: ingress-host-bar
spec:
  ingressClassName: nginx
  rules:
  - host: "hello.atguigu.com"
    http:
      paths:
      - pathType: Prefix
        path: "/"
        backend:
          service:
            name: hello-server
            port:
              number: 8000
  - host: "demo.atguigu.com"
    http:
      paths:
      - pathType: Prefix
        path: "/nginx"  # 把请求会转给下面的服务，下面的服务一定要能处理这个路径，不能处理就是404
        backend:
          service:
            name: nginx-demo  ## java，比如使用路径重写，去掉前缀nginx
            port:
              number: 8000
```
Ingress路劲重写
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress  
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
  name: ingress-host-bar
spec:
  ingressClassName: nginx
  rules:
  - host: "hello.atguigu.com"
    http:
      paths:
      - pathType: Prefix
        path: "/"
        backend:
          service:
            name: hello-server
            port:
              number: 8000
  - host: "demo.atguigu.com"
    http:
      paths:
      - pathType: Prefix
        path: "/nginx(/|$)(.*)"  # 把请求会转给下面的服务，下面的服务一定要能处理这个路径，不能处理就是404
        backend:
          service:
            name: nginx-demo  ## java，比如使用路径重写，去掉前缀nginx
            port:
              number: 8000
```
Ingress流量限制
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-limit-rate
  annotations:
    nginx.ingress.kubernetes.io/limit-rps: "1"
spec:
  ingressClassName: nginx
  rules:
  - host: "haha.atguigu.com"
    http:
      paths:
      - pathType: Exact
        path: "/"
        backend:
          service:
            name: nginx-demo
            port:
              number: 8000
```

# 二. 存储抽象
## 2.1 环境安装准备
```
#所有机器安装
yum install -y nfs-utils

#nfs主节点
echo "/nfs/data/ *(insecure,rw,sync,no_root_squash)" > /etc/exports
mkdir -p /nfs/data
systemctl enable rpcbind --now
systemctl enable nfs-server --now
#配置生效
exportfs -r

# 从节点
showmount -e 172.31.0.4
#执行以下命令挂载 nfs 服务器上的共享目录到本机路径 /root/nfsmount
mkdir -p /nfs/data
mount -t nfs 172.31.0.4:/nfs/data /nfs/data
# 写入一个测试文件
echo "hello nfs server" > /nfs/data/test.txt
```

使用原生方式的数据挂载  
原生的方式申请的空间不会被限制，存在无限变大的可能
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-pv-demo
  name: nginx-pv-demo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx-pv-demo
  template:
    metadata:
      labels:
        app: nginx-pv-demo
    spec:
      containers:
      - image: nginx
        name: nginx
        volumeMounts:
        - name: html  # 根据此处的name都下面找指定的挂载
          mountPath: /usr/share/nginx/html
      volumes:
        - name: html
          nfs:
            server: 172.26.196.170
            path: /mnt/nfs/data/nginx-pv  # pod删除后挂载到这里的文件不会被删除
```

## 2.2 PV&PVC
PV：持久卷（Persistent Volume），将应用需要持久化的数据保存到指定位置，例如上述就是一个PV持久卷     
PVC：持久卷申明（Persistent Volume Claim），申明需要使用的持久卷规格，创建pod时带着pvc申请指定大小的pv,如果删除pod会带着pvs一起删除，连带着申请的pv空间也会一同释放

### 2.2.1 静态供应
先创建好静态提供的PV池的文件夹
```
#nfs主节点
mkdir -p /mnt/nfs/data/pv/01
mkdir -p /mnt/nfs/data/pv/02
mkdir -p /mnt/nfs/data/pv/03
```
创建PV池  
kubectl get pv
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv01-10m
spec:
  capacity:
    storage: 10M
  accessModes:
    - ReadWriteMany
  storageClassName: nfs  # 需要和下面的一样
  nfs:
    path: /mnt/nfs/data/pv/01
    server: 172.26.196.170   # nfs主节点内网ip
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv02-1gi  # 需要小写
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  storageClassName: nfs
  nfs:
    path: /mnt/nfs/data/pv/02
    server: 172.26.196.170   # nfs主节点内网ip
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv03-3gi
spec:
  capacity:
    storage: 3Gi
  accessModes:
    - ReadWriteMany
  storageClassName: nfs
  nfs:
    path: /mnt/nfs/data/pv/03
    server: 172.26.196.170   # nfs主节点内网ip
```

创建PVC  
kubectl get pv  
根据申请要求会找一个pv绑定
```yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: nginx-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 200Mi
  storageClassName: nfs # 在名为nfs的pv中找一个符合条件的PV
```

创建Pod绑定PVC
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy-pvc
  name: nginx-deploy-pvc
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx-deploy-pvc
  template:
    metadata:
      labels:
        app: nginx-deploy-pvc
    spec:
      containers:
      - image: nginx
        name: nginx
        volumeMounts:
        - name: html
          mountPath: /usr/share/nginx/html
      volumes:
        - name: html
          persistentVolumeClaim:
            claimName: nginx-pvc # 必须事前存在了，必须事先把池子创建好，否则会找不到
```

### 2.2.2 动态供应


## 2.3 ConfigMap
抽取应用配置，并且可以自动更新，存储在etcd中  

下面以redis的pod创建过程为例子：   
+ 1. 创建配置集
```
# 新建一个文件redis.conf，内容为redis的配置参数，如： appendonly yes
# 创建配置，redis保存到k8s的etcd；
kubectl create cm redis-conf --from-file=redis.conf
```
上述创建完后可以通过命令`kubectl get cm redis-conf -oyaml`查看创建的yaml,也可以不用上述创建方式，直接通过yaml方式创建配置集，下面是对配置集精简后的yaml主要内容
```yaml
apiVersion: v1
data:    #data是所有真正的数据，key：默认是文件名   value：配置文件的内容, 具体的配置内容，相当于最终挂载的配置文件中的内容
  redis.conf: |
    appendonly yes
kind: ConfigMap
metadata:
  name: redis-conf  # 配置集名，后面通过该名称找到相应的配置集，再从配置集中找到对应的配置参数
  namespace: default
```

+ 2. 创建Pod
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: redis
spec:
  containers:
  - name: redis
    image: redis
    command:
      - redis-server # 启动指令
      - "/redis-master/redis.conf"  # redis容器内启动配置文件的位置
    ports:
    - containerPort: 6379
    volumeMounts: # 容器的挂载
    - mountPath: /data  # redis容器中存储数据的位置
      name: data   # 通过 data 字符串到下面的volumes挂载卷中查找名为 data 的配置集
    - mountPath: /redis-master  # redis容器中用来对应挂载配置文件的位置
      name: config # 通过 config 字符串到下面 volumes 挂载卷中找名为 config 的配置集
  volumes:  # 容器的挂载卷
    - name: data
      emptyDir: {}
    - name: config
      configMap:
        name: redis-conf  # 通过该名到配置集中查找一样名称的配置
        items:
        - key: redis.conf # 通过该key字符串到配置集data中找到对应的配置
          path: redis.conf  # 最终挂载的 redis-master 下的文件
```
相当于 docker run redis 


## 2.4 Secret
Secret 对象类型用来保存敏感信息，例如密码、OAuth 令牌和 SSH 密钥。 将这些信息放在 secret 中比放在 Pod 的定义或者 容器镜像 中来说更加安全和灵活。
```yaml
kubectl create secret docker-registry leifengyang-docker \
--docker-username=leifengyang \
--docker-password=Lfy123456 \
--docker-email=534096094@qq.com

##命令格式
kubectl create secret docker-registry regcred \
  --docker-server=<你的镜像仓库服务器> \
  --docker-username=<你的用户名> \
  --docker-password=<你的密码> \
  --docker-email=<你的邮箱地址>
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: private-nginx
spec:
  containers:
  - name: private-nginx
    image: leifengyang/guignginx:v1.0
  imagePullSecrets:
  - name: leifengyang-docker
```
